import time
import random
import re
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
import os

# ç®€åŒ–é…ç½®
SEARCH_CONFIG = {
    "location": "Berlin, Germany",  # å…ˆç”¨æŸæ—æµ‹è¯•
    "max_jobs": 10,  # å‡å°‘æ•°é‡æµ‹è¯•
    "work_types": ["hybrid", "on-site"]
}

class SimpleLinkedInScraper:
    def __init__(self):
        self.driver = None
        self.jobs_data = []
        
    def setup_driver(self):
        """è®¾ç½®æµè§ˆå™¨é©±åŠ¨"""
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        
        chrome_options = Options()
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36")
        
        service = Service()
        
        try:
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.implicitly_wait(10)
            print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼")
            return True
        except Exception as e:
            print(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def build_search_url(self):
        """æ„å»ºæœç´¢URL"""
        base_url = "https://www.linkedin.com/jobs/search/"
        params = [
            f"location={SEARCH_CONFIG['location']}",
            "f_TPR=r86400",  # 24å°æ—¶å†…
            "f_WT=1,3",      # ç°åœº+æ··åˆåŠå…¬
            "f_JT=F",        # å…¨èŒ
        ]
        return f"{base_url}?{'&'.join(params)}"
    
    def wait_for_manual_login(self):
        """ç­‰å¾…æ‰‹åŠ¨ç™»å½•"""
        print("ğŸ‘¤ è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•LinkedIn")
        print("   å®Œæˆç™»å½•åå›åˆ°è¿™é‡ŒæŒ‰å›è½¦ç»§ç»­...")
        input()
        time.sleep(3)
    
    def is_english_job(self, text):
        """ç®€å•è‹±æ–‡æ£€æµ‹"""
        if not text:
            return False, 0.0
        english_words = ['experience', 'skills', 'team', 'project', 'development']
        text_lower = text.lower()
        matches = sum(1 for word in english_words if word in text_lower)
        score = matches / len(english_words)
        return score >= 0.4, round(score, 2)
    
    def test_connection(self):
        """æµ‹è¯•è¿æ¥å’Œç™»å½•çŠ¶æ€"""
        try:
            print("ğŸŒ æµ‹è¯•è®¿é—®LinkedIn...")
            self.driver.get("https://www.linkedin.com")
            time.sleep(5)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨ç™»å½•çŠ¶æ€
            current_url = self.driver.current_url
            if "feed" in current_url or "jobs" in current_url:
                print("âœ… å·²å¤„äºç™»å½•çŠ¶æ€")
                return True
            else:
                print("âŒ éœ€è¦ç™»å½•")
                return False
                
        except Exception as e:
            print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def scrape_jobs_simple(self):
        """ç®€åŒ–ç‰ˆçˆ¬å–"""
        try:
            # å…ˆæµ‹è¯•è¿æ¥
            if not self.test_connection():
                self.wait_for_manual_login()
            
            # è®¿é—®æœç´¢é¡µé¢
            print("ğŸ” è®¿é—®æœç´¢é¡µé¢...")
            search_url = self.build_search_url()
            self.driver.get(search_url)
            time.sleep(8)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰èŒä½åˆ—è¡¨
            try:
                job_elements = self.driver.find_elements(By.CSS_SELECTOR, "li.jobs-search-results__list-item")
                print(f"ğŸ“Š æ‰¾åˆ° {len(job_elements)} ä¸ªèŒä½")
                
                if not job_elements:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°èŒä½åˆ—è¡¨ï¼Œå¯èƒ½é¡µé¢æœªæ­£ç¡®åŠ è½½")
                    return
                    
            except Exception as e:
                print(f"âŒ æŸ¥æ‰¾èŒä½åˆ—è¡¨å¤±è´¥: {e}")
                return
            
            # åªå¤„ç†å‰å‡ ä¸ªèŒä½æµ‹è¯•
            for i in range(min(3, len(job_elements))):
                try:
                    print(f"\nğŸ“‹ å¤„ç†ç¬¬ {i+1} ä¸ªèŒä½")
                    
                    # ç‚¹å‡»èŒä½
                    job_elements = self.driver.find_elements(By.CSS_SELECTOR, "li.jobs-search-results__list-item")
                    if i >= len(job_elements):
                        break
                        
                    job_elements[i].click()
                    time.sleep(3)
                    
                    # æå–åŸºæœ¬ä¿¡æ¯
                    job_info = self.extract_simple_info()
                    if job_info:
                        is_english, score = self.is_english_job(job_info.get('description', ''))
                        job_info['is_english'] = is_english
                        job_info['english_score'] = score
                        
                        self.jobs_data.append(job_info)
                        print(f"   âœ… æˆåŠŸæå–: {job_info['title']}")
                    
                    time.sleep(2)
                    
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†èŒä½ {i+1} å¤±è´¥: {e}")
                    continue
            
            print(f"\nğŸ‰ æˆåŠŸå¤„ç† {len(self.jobs_data)} ä¸ªèŒä½")
            
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
    
    def extract_simple_info(self):
        """ç®€åŒ–ä¿¡æ¯æå–"""
        try:
            info = {}
            
            # æ ‡é¢˜
            try:
                title_elements = self.driver.find_elements(By.TAG_NAME, "h2")
                for elem in title_elements:
                    text = elem.text.strip()
                    if text and len(text) > 5:
                        info['title'] = text
                        break
                if 'title' not in info:
                    info['title'] = "Unknown"
            except:
                info['title'] = "Unknown"
            
            # å…¬å¸
            try:
                company_elements = self.driver.find_elements(By.CSS_SELECTOR, "[data-tracking-control-name='public_jobs_jserp-result_job-search-card-subtitle']")
                if company_elements:
                    info['company'] = company_elements[0].text.strip()
                else:
                    info['company'] = "Unknown"
            except:
                info['company'] = "Unknown"
            
            # åœ°ç‚¹
            try:
                location_elements = self.driver.find_elements(By.CSS_SELECTOR, "[class*='location'], [data-tracking-control-name*='location']")
                if location_elements:
                    info['location'] = location_elements[0].text.strip()
                else:
                    info['location'] = "Unknown"
            except:
                info['location'] = "Unknown"
            
            # æè¿°
            try:
                desc_elements = self.driver.find_elements(By.ID, "job-details")
                if desc_elements:
                    info['description'] = desc_elements[0].text.strip()
                else:
                    info['description'] = ""
            except:
                info['description'] = ""
            
            info['job_url'] = self.driver.current_url
            info['scraped_at'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
            
            return info
            
        except Exception as e:
            print(f"âš ï¸ æå–ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        if not self.jobs_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return False
        
        try:
            df = pd.DataFrame(self.jobs_data)
            filename = "test_jobs.xlsx"
            
            # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—
            if 'title' not in df.columns:
                df['title'] = 'Unknown'
            if 'company' not in df.columns:
                df['company'] = 'Unknown'
            if 'location' not in df.columns:
                df['location'] = 'Unknown'
            
            df.to_excel(filename, index=False)
            print(f"ğŸ’¾ æˆåŠŸä¿å­˜åˆ°: {filename}")
            print(f"ğŸ“Š ä¿å­˜äº† {len(df)} è¡Œæ•°æ®")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            print("ğŸ”š æµè§ˆå™¨å·²å…³é—­")

def main():
    print("=" * 50)
    print("ğŸ”§ LinkedInè°ƒè¯•ç‰ˆ")
    print("=" * 50)
    
    scraper = SimpleLinkedInScraper()
    
    try:
        # 1. å¯åŠ¨æµè§ˆå™¨
        if not scraper.setup_driver():
            return
        
        # 2. çˆ¬å–æ•°æ®
        scraper.scrape_jobs_simple()
        
        # 3. ä¿å­˜ç»“æœ
        if scraper.jobs_data:
            success = scraper.save_results()
            if success:
                print("\nğŸ¯ è°ƒè¯•å®Œæˆï¼æ£€æŸ¥ test_jobs.xlsx æ–‡ä»¶")
            else:
                print("\nâŒ ä¿å­˜å¤±è´¥")
        else:
            print("\nâŒ æ²¡æœ‰è·å–åˆ°æ•°æ®")
            
    except Exception as e:
        print(f"ğŸ’¥ ç¨‹åºå‡ºé”™: {e}")
    finally:
        scraper.close()

if __name__ == "__main__":
    main()
